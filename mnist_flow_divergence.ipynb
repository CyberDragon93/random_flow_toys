{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505148f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from rectified_flow.rectified_flow import RectifiedFlow\n",
    "from rectified_flow.utils import match_dim_with_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "transform_list = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "]\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.Compose(transform_list)\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,          \n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)  # torch.Size([256, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1177dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"unet\"\n",
    "from rectified_flow.models.enhanced_mlp import VarMLP\n",
    "from rectified_flow.models.utils import EMAModel\n",
    "from rectified_flow.models.unet import SongUNet, SongUNetConfig\n",
    "\n",
    "flow_model = SongUNet.from_pretrained(\"/scratch/10992/liaorunlong93/random_flow_toys/checkpoints/flow_mnist_unet_unconditional\", use_ema=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecd57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler, SDESampler\n",
    "from rectified_flow.utils import plot_cifar_results\n",
    "\n",
    "rf = RectifiedFlow(\n",
    "    data_shape=(1, 28, 28),\n",
    "    velocity_field=flow_model,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "x_0_src = torch.randn(50, 1, 28, 28, device=device)\n",
    "\n",
    "sampler = EulerSampler(rectified_flow=rf, num_steps=200)\n",
    "rf_samples = sampler.sample_loop(x_0=x_0_src).trajectories[-1]\n",
    "\n",
    "sde_sampler = SDESampler(rectified_flow=rf, num_steps=100, noise_decay_rate=0.0, noise_scale=50.0)\n",
    "rf_sde_samples = sde_sampler.sample_loop(x_0=x_0_src).trajectories[-1]\n",
    "\n",
    "plot_cifar_results(rf_samples)\n",
    "plot_cifar_results(rf_sde_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e19969",
   "metadata": {},
   "source": [
    "## Implement divergence estimation and verify correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f0a9d",
   "metadata": {},
   "source": [
    "### Exact Jacobian calculation with autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "def divergence_exact_manual(v_func, x_t, t):\n",
    "    device, dtype = x_t.device, x_t.dtype\n",
    "    B = x_t.shape[0]\n",
    "    div = torch.empty(B, device=device, dtype=dtype)\n",
    "\n",
    "    for b in tqdm(range(B), desc=\"Computing exact divergence\"):\n",
    "        xb = x_t[b:b+1].detach().requires_grad_(True)\n",
    "        tb = t[b:b+1]\n",
    "\n",
    "        def f(inp):\n",
    "            return v_func(inp, tb)\n",
    "\n",
    "        J = jacobian(f, xb, vectorize=False, create_graph=False)\n",
    "        D = xb.numel()\n",
    "        div[b] = J.reshape(D, D).diagonal().sum().to(dtype)\n",
    "        del J\n",
    "        \n",
    "    return div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557fac7",
   "metadata": {},
   "source": [
    "### Divergence Estimation via the Hutchinson Trick\n",
    "\n",
    "For a vector field $v(x,t)$ with Jacobian $J(x) = \\dfrac{\\partial v}{\\partial x}$, the divergence is\n",
    "$$\n",
    "\\operatorname{div} v(x,t) = \\operatorname{tr}\\, J(x).\n",
    "$$\n",
    "Computing $\\operatorname{tr} J$ via an explicit Jacobian is expensive. The Hutchinson identity gives an unbiased estimator:\n",
    "$$\n",
    "\\operatorname{tr} J = \\mathbb{E}_{\\varepsilon}\\!\\left[\\varepsilon^\\top J \\varepsilon\\right],\n",
    "$$\n",
    "where $\\varepsilon$ can be Rademacher ($\\pm1$ w.p. 1/2) or standard Gaussian. A Monte Carlo estimate is\n",
    "$$\n",
    "\\widehat{\\operatorname{div}}(x,t) = \\frac{1}{M}\\sum_{i=1}^{M} \\varepsilon_i^\\top (J\\,\\varepsilon_i),\n",
    "$$\n",
    "which only requires Jacobian–vector products (JVP) or vector–Jacobian products (VJP), avoiding materializing the full Jacobian.\n",
    "\n",
    "**Implementation notes**\n",
    "- `eps_dist=\"rademacher\"` often yields slightly lower variance; `\"normal\"` works too.\n",
    "- Use forward-mode `jvp` to get $J\\varepsilon$, or a single backward (VJP) to get $J^\\top \\varepsilon$ and then dot with $\\varepsilon$.\n",
    "- Compute per-sample inner products in the batch and average across $M$ probes; `M=1–4` is typically sufficient.\n",
    "- When using fp16/bf16, accumulate in fp32 for numerical stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761184e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jvp as jvp_func\n",
    "\n",
    "def divergence_hutchinson(\n",
    "    v_func,\n",
    "    x_t: torch.Tensor,\n",
    "    t: torch.Tensor,\n",
    "    n_samples: int = 20,\n",
    "    eps_dist: str = \"rademacher\",\n",
    "    method: str = \"vjp\",\n",
    ") -> torch.Tensor:\n",
    "    device, dtype = x_t.device, x_t.dtype\n",
    "    B = x_t.shape[0]\n",
    "    D = x_t.numel() // B\n",
    "\n",
    "    x_flat = x_t.detach().view(B, D)\n",
    "\n",
    "    acc_dtype = torch.float32 if dtype in (torch.float16, torch.bfloat16) else dtype\n",
    "    acc = torch.zeros(B, device=device, dtype=acc_dtype)\n",
    "\n",
    "    def _sample_eps_flat():\n",
    "        if eps_dist == \"rademacher\":\n",
    "            r = torch.randint(0, 2, (B, D), device=device)\n",
    "            eps = (r * 2 - 1).to(acc_dtype)\n",
    "        elif eps_dist == \"normal\":\n",
    "            eps = torch.randn((B, D), device=device, dtype=acc_dtype)\n",
    "        else:\n",
    "            raise ValueError(\"eps_dist must be 'rademacher' or 'normal'\")\n",
    "        return eps.to(dtype)\n",
    "\n",
    "    if method == \"jvp\":\n",
    "        def f_flat(inp_flat):\n",
    "            x4 = inp_flat.view(B, *x_t.shape[1:])\n",
    "            y4 = v_func(x4, t)\n",
    "            return y4.view(B, D)\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            eps_flat = _sample_eps_flat()\n",
    "            _, jvp_out = jvp_func(f_flat, (x_flat,), (eps_flat,), strict=False)  # <-- fix\n",
    "            acc += (eps_flat * jvp_out).sum(dim=1).to(acc_dtype)\n",
    "\n",
    "        return (acc / n_samples).to(dtype)\n",
    "\n",
    "    elif method == \"vjp\":\n",
    "        for _ in range(n_samples):\n",
    "            eps_flat = _sample_eps_flat()\n",
    "            eps = eps_flat.view_as(x_t)\n",
    "            x_req = x_t.detach().requires_grad_(True)\n",
    "            v = v_func(x_req, t)\n",
    "            s_per_sample = (v * eps).view(B, -1).sum(dim=1)\n",
    "            gx = torch.autograd.grad(\n",
    "                s_per_sample.sum(), x_req, create_graph=False, retain_graph=False\n",
    "            )[0]\n",
    "            acc += (gx.detach() * eps).view(B, -1).sum(dim=1).to(acc_dtype)\n",
    "            del x_req, v, gx, eps, eps_flat, s_per_sample\n",
    "\n",
    "        return (acc / n_samples).to(dtype)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'jvp' or 'vjp'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ad356",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = batch[0].to(device)[233:234]\n",
    "x_1 = x_1.repeat_interleave(6, dim=0)\n",
    "t = torch.linspace(0.95, 1.0, steps=x_1.shape[0], device=device)\n",
    "x_t = t[:, None, None, None] * x_1 + (1 - t)[:, None, None, None] * torch.randn_like(x_1)\n",
    "\n",
    "div_exact = divergence_exact_manual(flow_model, x_t, t)\n",
    "div_approx = divergence_hutchinson(flow_model, x_t, t, n_samples=20, method=\"vjp\")\n",
    "\n",
    "print(\"Divergence shape:\", div_exact.shape)\n",
    "print(\"div exact:\", div_exact)\n",
    "print(\"div approx:\", div_approx)\n",
    "print(\"Max absolute error:\", (div_exact - div_approx).abs().max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b341a962",
   "metadata": {},
   "source": [
    "## log prob estimation with Simultaneous change of variable\n",
    "\n",
    "\n",
    "$$\n",
    "\\log \\rho_t(x^{\\mathrm{eval}}) \n",
    "= \n",
    "\\log \\rho_0(z_0^{\\mathrm{eval}}) \n",
    "- \n",
    "\\int_0^1 \\nabla \\cdot v_t(z_t^{\\mathrm{eval}}) \\, \\mathrm dt,\n",
    "$$\n",
    "\n",
    "where $ \\{ z_t^{\\mathrm{eval}} \\} $ is the solution of \n",
    "\n",
    "$$\n",
    "\\dot{z}_t^{\\mathrm{eval}} = v_t(z_t^{\\mathrm{eval}}), \n",
    "\\quad \\text{with} \\quad \n",
    "z_1^{\\mathrm{eval}} = x^{\\mathrm{eval}}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 30\n",
    "\n",
    "x_eval = batch[0].to(device)[:n_samples]\n",
    "x_eval = torch.cat([\n",
    "        rf_samples[:n_samples],     # ODE inv\n",
    "        rf_sde_samples[:n_samples], # SDE inv\n",
    "        x_eval,              # Test set inv\n",
    "    ], dim=0)\n",
    "alpha = 0.01\n",
    "x_eval = (1. - alpha) * x_eval + alpha * torch.randn_like(x_eval)\n",
    "# x_eval = x_1\n",
    "N = 1000\n",
    "plot_cifar_results(x_eval)\n",
    "\n",
    "# Generate an ODE trajectory for evaluation\n",
    "time_grid = torch.linspace(0., 1. - alpha, N, device=device)\n",
    "inv_rf = RectifiedFlow(\n",
    "    data_shape=(1, 28, 28),\n",
    "    velocity_field=lambda x, t: -flow_model(x, 1. - t),\n",
    "    device=device,\n",
    ")\n",
    "sampler_inv = EulerSampler(rectified_flow=inv_rf, time_grid=time_grid)\n",
    "x_0_inv = sampler_inv.sample_loop(x_0=x_eval).trajectories[-1]\n",
    "x_0_inv = torch.cat((x_0_src[:n_samples], x_0_inv), dim=0) # [ODE vanilla, ODE inv, SDE inv, Test set inv]\n",
    "plot_cifar_results(x_0_inv)\n",
    "\n",
    "# Now generate samples from x_0_inv back to x_eval, to see how well we reconstruct\n",
    "rf = RectifiedFlow(\n",
    "    data_shape=(1, 28, 28),\n",
    "    velocity_field=flow_model,\n",
    "    device=device,\n",
    ")\n",
    "sampler = EulerSampler(rectified_flow=rf, num_samples=50, num_steps=N)\n",
    "x_1 = sampler.sample_loop(x_0=x_0_inv).trajectories[-1]\n",
    "plot_cifar_results(x_1)\n",
    "plot_cifar_results(torch.abs(x_1[n_samples:] - x_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "x = x_0_inv.view(-1).cpu().numpy()\n",
    "sns.histplot(x, kde=True, stat=\"density\")\n",
    "mu, sigma = x.mean(), x.std()\n",
    "xs = np.linspace(x.min(), x.max(), 200)\n",
    "plt.plot(xs, stats.norm.pdf(xs, mu, sigma), 'r--', label='Normal fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_normal_logprob(z):\n",
    "    B = z.shape[0]\n",
    "    zf = z.view(B, -1)\n",
    "    D = zf.shape[1]\n",
    "    return -0.5 * (zf.pow(2).sum(dim=1) + D * math.log(2 * math.pi))\n",
    "\n",
    "def estimate_logprob_from_inverse(\n",
    "    x_0_inv: torch.Tensor,\n",
    "    rf,                      \n",
    "    flow_model,\n",
    "    N: int = 300,\n",
    "    alpha: float = 0.0,       \n",
    "    sample_stride: int = 5,\n",
    "):\n",
    "    device = x_0_inv.device\n",
    "    B = x_0_inv.shape[0]\n",
    "\n",
    "    t1 = max(0.0, 1.0 - alpha)\n",
    "    time_grid = torch.linspace(0., t1, N, device=device)\n",
    "\n",
    "    sampler_fwd = EulerSampler(rectified_flow=rf, time_grid=time_grid)\n",
    "    traj = sampler_fwd.sample_loop(x_0=x_0_inv).trajectories\n",
    "    states = torch.stack(traj, dim=0) if isinstance(traj, list) else traj     # (T, B, C, H, W)\n",
    "    T = states.shape[0]\n",
    "\n",
    "    idx = torch.arange(0, T, sample_stride, device=device)\n",
    "    if idx[-1].item() != T - 1:\n",
    "        idx = torch.cat([idx, torch.tensor([T - 1], device=device)])\n",
    "    t_used = time_grid.index_select(0, idx)               # (Ts,)\n",
    "    x_used = states.index_select(0, idx)                  # (Ts, B, C, H, W)\n",
    "\n",
    "    div_values = []\n",
    "    for k in tqdm(range(t_used.shape[0]), desc=\"Computing divergences\"):\n",
    "        tk = t_used[k]\n",
    "        xk = x_used[k]                                     # (B, C, H, W)\n",
    "        tb = torch.full((B,), tk.item(), device=device)    # (B,)\n",
    "        div_k = divergence_hutchinson(flow_model, xk, tb, n_samples=30)  # (B,)\n",
    "        div_values.append(div_k)\n",
    "        print(f\"Time {tk.item():.5f} divergence mean: {div_k.mean().item():.4f}\")\n",
    "    divs = torch.stack(div_values, dim=0)                  # (Ts, B)\n",
    "\n",
    "    int_div = torch.trapz(divs, t_used, dim=0)            # (B,)\n",
    "    log_rho0 = standard_normal_logprob(x_0_inv)           # (B,)\n",
    "    log_rho_eval = log_rho0 - int_div                     # (B,)\n",
    "\n",
    "    details = {\n",
    "        \"time_grid_full\": time_grid,   # (T,)\n",
    "        \"time_grid_used\": t_used,      # (Ts,)\n",
    "        \"states_used\": x_used,         # (Ts, B, C, H, W)\n",
    "        \"divergences\": divs,           # (Ts, B)\n",
    "        \"int_divergence\": int_div,     # (B,)\n",
    "        \"log_rho0\": log_rho0,          # (B,)\n",
    "    }\n",
    "    return log_rho_eval, details\n",
    "\n",
    "log_rho_eval, details = estimate_logprob_from_inverse(\n",
    "    x_0_inv=x_0_inv,\n",
    "    rf=rf,\n",
    "    flow_model=flow_model,\n",
    "    N=1000,\n",
    "    alpha=0.0,\n",
    "    sample_stride=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ODE vanilla, ODE inv, SDE inv, Test set inv]\n",
    "\n",
    "print(\"ODE_vanilla logp mean\",log_rho_eval[:n_samples].mean())\n",
    "\n",
    "print(\"ODE_inv logp mean\",log_rho_eval[n_samples:2*n_samples].mean())\n",
    "\n",
    "print(\"SDE_inv logp mean\",log_rho_eval[2*n_samples:3*n_samples].mean())\n",
    "\n",
    "print(\"Test_set logp mean\",log_rho_eval[3*n_samples:4*n_samples].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpd_from_logrho(log_rho, D, b=8, a=1.0):\n",
    "    # logrho: per-sample log ρ1(x) in nats (model coordinate)\n",
    "    # D: H*W*C,  a: per-dim linear scale from y∈[0,1] to x (e.g., a=2 for [-1,1])\n",
    "    import math\n",
    "    return -log_rho / (D * math.log(2.0)) + b - math.log2(a)\n",
    "\n",
    "bpd_eval = bpd_from_logrho(log_rho_eval, D=28*28*1, b=8, a=1.0)\n",
    "print(\"BPD Eval mean:\", bpd_eval.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "details[\"log_rho0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9484df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_images_with_logrho(\n",
    "    images: torch.Tensor,\n",
    "    log_rho: torch.Tensor,\n",
    "    nrow: int = 10,\n",
    "    title: str | None = None,\n",
    "    digits: int = 2,\n",
    "    dpi: int = 300,\n",
    "    fontsize: int = 8,\n",
    "    normalize_from_neg1_pos1: bool = True,\n",
    "    save_path: str | None = None,\n",
    "    group_titles: list[str] | None = None,\n",
    "    group_size: int | None = None,\n",
    "    show_group_mean: bool = False,\n",
    "):\n",
    "    import math\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import gridspec\n",
    "\n",
    "    assert images.ndim == 4, \"images should be (B, C, H, W)\"\n",
    "    B = images.shape[0]\n",
    "    cols = min(nrow, B)\n",
    "\n",
    "    imgs = images.detach().cpu().clone()\n",
    "    if normalize_from_neg1_pos1:\n",
    "        imgs = (imgs * 0.5 + 0.5).clamp(0, 1)\n",
    "\n",
    "    scores = log_rho.detach().cpu().view(-1)\n",
    "    assert scores.numel() == B, \"log_rho length must match number of images\"\n",
    "\n",
    "    # 分段\n",
    "    groups = []\n",
    "    if group_titles is not None and group_size is not None:\n",
    "        total_needed = group_size * len(group_titles)\n",
    "        assert total_needed <= B, \"group_size * len(group_titles) exceeds number of images\"\n",
    "        start = 0\n",
    "        for name in group_titles:\n",
    "            end = start + group_size\n",
    "            groups.append((name, start, end))\n",
    "            start = end\n",
    "    else:\n",
    "        groups.append((\"All\", 0, B))\n",
    "\n",
    "    rows_per_group = [math.ceil((e - s) / cols) for _, s, e in groups]\n",
    "\n",
    "    col_width  = 1.35\n",
    "    row_height = 1.30\n",
    "    title_frac = 0.10     \n",
    "    group_hspace = 0.16   \n",
    "    cell_hspace  = 0.08   \n",
    "    cell_wspace  = 0.03   \n",
    "\n",
    "    fig_w = cols * col_width\n",
    "    fig_h = sum(r * row_height + title_frac * row_height for r in rows_per_group)\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_w, fig_h), dpi=dpi)\n",
    "    outer = gridspec.GridSpec(\n",
    "        nrows=len(groups), ncols=1,\n",
    "        height_ratios=[(title_frac + r) for r in rows_per_group],\n",
    "        hspace=group_hspace,\n",
    "    )\n",
    "\n",
    "    for gi, (gname, s, e) in enumerate(groups):\n",
    "        r = rows_per_group[gi]\n",
    "        sub = outer[gi].subgridspec(\n",
    "            r + 1, cols,\n",
    "            height_ratios=[title_frac] + [1]*r,\n",
    "            wspace=cell_wspace, hspace=cell_hspace\n",
    "        )\n",
    "\n",
    "        ax_title = fig.add_subplot(sub[0, :])\n",
    "        ax_title.axis(\"off\")\n",
    "        if show_group_mean:\n",
    "            mean_val = scores[s:e].mean().item()\n",
    "            txt = f\"{gname}  (mean log ρ = {mean_val:.{digits}f})\"\n",
    "        else:\n",
    "            txt = gname\n",
    "        ax_title.text(0.0, 0.5, txt, fontsize=fontsize+1, va=\"center\", ha=\"left\")\n",
    "\n",
    "        for k in range(r * cols):\n",
    "            ax = fig.add_subplot(sub[1 + k // cols, k % cols])\n",
    "            idx = s + k\n",
    "            if idx < e:\n",
    "                img = imgs[idx]\n",
    "                if img.shape[0] == 1:\n",
    "                    ax.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "                else:\n",
    "                    ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "                ax.set_xticks([]); ax.set_yticks([])\n",
    "                for sp in ax.spines.values():\n",
    "                    sp.set_visible(False)\n",
    "\n",
    "                # 把分数放到图内左下角，避免 xlabel 留白\n",
    "                label = f\"{scores[idx].item():.{digits}f}\"\n",
    "                ax.text(\n",
    "                    0.02, 0.02, label,\n",
    "                    transform=ax.transAxes, ha=\"left\", va=\"bottom\",\n",
    "                    fontsize=fontsize, color=\"white\",\n",
    "                    bbox=dict(facecolor=\"black\", alpha=0.35, pad=1.0, edgecolor=\"none\"),\n",
    "                )\n",
    "            else:\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=12, y=0.995)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_images_with_logrho(\n",
    "    images=details[\"states_used\"][-1],\n",
    "    log_rho=log_rho_eval[:],\n",
    "    nrow=10,\n",
    "    title=\"Samples with log ρ\",\n",
    "    digits=2,\n",
    "    dpi=300,\n",
    "    fontsize=8,\n",
    "    group_titles=[\"ODE vanilla\", \"ODE inv\", \"SDE inv\", \"Test set inv\"],\n",
    "    group_size=n_samples,\n",
    "    show_group_mean=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66e604",
   "metadata": {},
   "source": [
    "## Log Likelihood Estimation from KL Divergence \n",
    "\n",
    "For a given data point  $x^{\\mathrm{eval}} $, we can derive the following formula for log likelihood:\n",
    "\n",
    "$$\n",
    "\\log \\rho_t(x^{\\mathrm{eval}}) \n",
    "= \\int_0^1 \\frac{t}{1 - t} \n",
    "\\, \\mathbb{E}\\!\\left[ \n",
    "\\| \\dot{X}_t^{\\mathrm{eval}} \\|^2 \n",
    "- \n",
    "\\| \\dot{X}_t^{\\mathrm{eval}} - v_t(X_t^{\\mathrm{eval}}) \\|^2 \n",
    "\\right] \\mathrm dt \n",
    "\\tag{*}\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "X_t^{\\mathrm{eval}} = t x^{\\mathrm{eval}} + (1 - t) X_0,\n",
    "\\quad \\text{with } X_0 \\sim \\mathrm{Normal}(0, I).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = details[\"states_used\"][-1]\n",
    "\n",
    "print(x_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loglik_from_KL_chunked(\n",
    "    v_func,\n",
    "    x_eval: torch.Tensor,\n",
    "    n_t: int = 64,\n",
    "    n_x0: int = 256,\n",
    "    t_eps: float = 1e-3,\n",
    "    x0_chunk: int = 64,\n",
    "    acc_dtype: torch.dtype = torch.float32,\n",
    "):\n",
    "    assert 0.0 < t_eps < 0.5\n",
    "    device, fwd_dtype = x_eval.device, x_eval.dtype\n",
    "    B = x_eval.shape[0]\n",
    "    rest_shape = x_eval.shape[1:]\n",
    "    D = int(torch.tensor(rest_shape).prod().item()) if len(rest_shape) else 1\n",
    "\n",
    "    X0_full = torch.randn((B, n_x0, *rest_shape), device=device, dtype=fwd_dtype)\n",
    "\n",
    "    grid = torch.arange(n_t, device=device, dtype=acc_dtype)\n",
    "    t_grid = (grid + 0.5) / n_t\n",
    "    t_grid = t_eps + (1.0 - 2.0 * t_eps) * t_grid\n",
    "    delta_t = (1.0 - 2.0 * t_eps) / n_t\n",
    "    t_weights = (t_grid / (1.0 - t_grid)) * delta_t  # (n_t,)\n",
    "\n",
    "    out = torch.zeros((B,), device=device, dtype=acc_dtype)\n",
    "    x_eval_u1_fwd = x_eval.unsqueeze(1)  # (B,1,...)\n",
    "\n",
    "    for t_acc, w in tqdm(zip(t_grid, t_weights), total=n_t):\n",
    "        t = t_acc.to(fwd_dtype)\n",
    "        w = w.to(acc_dtype)\n",
    "\n",
    "        accum_b = torch.zeros((B,), device=device, dtype=acc_dtype)\n",
    "\n",
    "        for i in range(0, n_x0, x0_chunk):\n",
    "            csz = min(x0_chunk, n_x0 - i)\n",
    "\n",
    "            X0_chunk = X0_full[:, i:i+csz]  # fwd_dtype\n",
    "            x_t_chunk = t * x_eval_u1_fwd + (1.0 - t) * X0_chunk\n",
    "\n",
    "            a_flat = (\n",
    "                x_eval_u1_fwd.to(acc_dtype).expand(-1, csz, *rest_shape)\n",
    "                - X0_chunk.to(acc_dtype)\n",
    "            ).reshape(B * csz, -1)  # (B*csz, D)\n",
    "\n",
    "            x_t_flat = x_t_chunk.reshape(B * csz, *rest_shape)  # fwd_dtype\n",
    "            t_vec = torch.full((B * csz,), float(t.item()), device=device, dtype=fwd_dtype)\n",
    "            v = v_func(x_t_flat, t_vec)\n",
    "\n",
    "            v_flat = v.reshape(B * csz, -1).to(acc_dtype)\n",
    "\n",
    "            contrib = 2.0 * (a_flat * v_flat).sum(dim=1) - (v_flat * v_flat).sum(dim=1)\n",
    "            contrib = contrib.view(B, csz).sum(dim=1)\n",
    "\n",
    "            accum_b += contrib\n",
    "\n",
    "        out += w * (accum_b / float(n_x0))\n",
    "\n",
    "    return out\n",
    "\n",
    "result = estimate_loglik_from_KL_chunked(\n",
    "    v_func=flow_model,\n",
    "    x_eval=x_1,\n",
    "    n_t=50,\n",
    "    n_x0=128,\n",
    "    t_eps=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbaa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_with_logrho(\n",
    "    images=details[\"states_used\"][-1],\n",
    "    log_rho=result,\n",
    "    nrow=10,\n",
    "    title=\"Samples with log ρ\",\n",
    "    digits=2,\n",
    "    dpi=300,\n",
    "    fontsize=8,\n",
    "    group_titles=[\"ODE vanilla\", \"ODE inv\", \"SDE inv\", \"Test set inv\"],\n",
    "    group_size=n_samples,\n",
    "    show_group_mean=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
