{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d4d992",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Try flow MNIST with UNet MLP, UNet / DiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f20ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from rectified_flow.rectified_flow import RectifiedFlow\n",
    "from rectified_flow.utils import match_dim_with_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48eb2cd",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "## Load dataset, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "transform_list = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "]\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transforms.Compose(transform_list)\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,          \n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)  # torch.Size([256, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817da497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"unet\"    # \"mlp\" or \"unet\" or \"dit\"\n",
    "from rectified_flow.models.enhanced_mlp import VarMLP\n",
    "from rectified_flow.models.utils import EMAModel\n",
    "\n",
    "if model_type == \"mlp\":\n",
    "    from rectified_flow.models.enhanced_mlp import MLPVelocity\n",
    "    flow_model = MLPVelocity(\n",
    "        dim=28*28,\n",
    "        encoder_dims=[256, 512, 512],\n",
    "        decoder_dims=[512, 512, 256],\n",
    "        time_emb_dim = 512,\n",
    "    )\n",
    "    data_shape = (28*28,)\n",
    "elif model_type == \"unet\":\n",
    "    from rectified_flow.models.unet import SongUNet, SongUNetConfig\n",
    "    config = SongUNetConfig(\n",
    "        img_resolution = 28,\n",
    "        in_channels = 1,                  # Number of color channels at input.\n",
    "        out_channels = 1,                 # Number of color channels at output.\n",
    "        label_dim = 0,                    # Number of class labels, 0 = unconditional.\n",
    "        augment_dim = 0,                  # Augmentation label dimensionality, 0 = no augmentation.\n",
    "\n",
    "        model_channels = 64,                # Base multiplier for the number of channels.\n",
    "        channel_mult = [2, 2],              # Channel multipliers for each resolution.\n",
    "        channel_mult_emb = 2,               # Multiplier for the dimensionality of the embedding vector.\n",
    "        num_blocks = 2,                     # Number of residual blocks per resolution.\n",
    "        attn_resolutions = [14],            # Resolutions at which to apply attention.\n",
    "        dropout = 0.13,                     # Dropout probability of intermediate activations.\n",
    "        label_dropout = 0.0,                # Dropout probability of class labels for classifier-free guidance.\n",
    "        embedding_type = \"positional\",      # Timestep embedding type: 'positional' or 'fourier'.\n",
    "        channel_mult_time = 1,              # Timestep embedding size: 1 for DDPM++, 2 for NCSN++.\n",
    "        encoder_type = \"standard\",          # Encoder architecture: 'standard' or 'residual'.\n",
    "        decoder_type = \"standard\",          # Decoder architecture: 'standard' or 'residual'.\n",
    "        resample_filter = [1, 1]\n",
    "    )\n",
    "\n",
    "    # config = SongUNetConfig(\n",
    "    #     img_resolution=28,\n",
    "    #     in_channels=1,\n",
    "    #     out_channels=1,\n",
    "    #     label_dim=0,\n",
    "    #     augment_dim=0,\n",
    "    #     model_channels=128,\n",
    "    #     channel_mult=[2, 2, 2],\n",
    "    #     channel_mult_emb=4,\n",
    "    #     num_blocks=4,\n",
    "    #     attn_resolutions=[14],\n",
    "    #     dropout=0.13,\n",
    "    #     label_dropout=0.0,\n",
    "    #     embedding_type=\"positional\",\n",
    "    #     channel_mult_time=1,\n",
    "    #     encoder_type=\"standard\",\n",
    "    #     decoder_type=\"standard\",\n",
    "    #     resample_filter=[1, 1],\n",
    "    # )\n",
    "    flow_model = SongUNet(config)\n",
    "    data_shape = (1, 28, 28)\n",
    "elif model_type == \"dit\":\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "logvar = VarMLP().to(device)\n",
    "flow_model = flow_model.to(device)\n",
    "\n",
    "print(f\"Number of parameters in flow model: {sum(p.numel() for p in flow_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "ema_flow = EMAModel(flow_model, ema_halflife_kimg=1.0, ema_rampup_ratio=0.05)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(flow_model.parameters()) + list(logvar.parameters()),\n",
    "    lr=5e-4, weight_decay=0.01,\n",
    "    betas=(0.9, 0.95)\n",
    ")\n",
    "\n",
    "compiled_flow = torch.compile(flow_model, mode=\"reduce-overhead\", fullgraph=False, dynamic=False)\n",
    "compiled_logvar = torch.compile(logvar, mode=\"reduce-overhead\", fullgraph=False, dynamic=False)\n",
    "\n",
    "compiled_flow.train(); compiled_logvar.train()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4fcfb",
   "metadata": {},
   "source": [
    "## Train Unconditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200\n",
    "cur_nimg = 0\n",
    "\n",
    "rf_train = RectifiedFlow(\n",
    "    data_shape=data_shape,\n",
    "    velocity_field=compiled_flow,\n",
    "    train_time_distribution=\"uniform\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "def safe_tqdm_write(msg: str):\n",
    "    try:\n",
    "        tqdm.write(msg)\n",
    "    except Exception:\n",
    "        print(msg)\n",
    "\n",
    "zero_to_none = True\n",
    "grad_clip_norm = None\n",
    "\n",
    "global_step = 0\n",
    "running_loss = None\n",
    "smooth_alpha = 0.99\n",
    "\n",
    "# test model\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(train_dataloader))\n",
    "    x_1, c = batch\n",
    "    x_1 = x_1.to(device, non_blocking=True).reshape(x_1.shape[0], *data_shape)\n",
    "    x_0 = torch.randn_like(x_1)\n",
    "    t = rf_train.sample_train_time(x_1.shape[0]).to(device, non_blocking=True)\n",
    "    v_pred = flow_model(x_1, t)\n",
    "    print(x_1.shape, x_0.shape, v_pred.shape)\n",
    "    log_var = logvar(t)[:, None, None, None]  # [B] or [B,1]\n",
    "    denom = torch.exp(log_var)\n",
    "    print(log_var.shape, denom.shape)\n",
    "    sq_err = (v_pred - (x_1 - x_0)).pow(2).sum(dim=1)\n",
    "    loss = (sq_err / denom + log_var).mean()\n",
    "    safe_tqdm_write(f\"Initial test loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af5e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15/200] steps=1,770 mse_loss=0.1681, mse_loss_ema=0.1751, logvar_loss=-0.7839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ad985b749d424dbce7dee32969bdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 16/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16/200] steps=1,888 mse_loss=0.1731, mse_loss_ema=0.1748, logvar_loss=-0.7534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d0365377e64e92a914b12395351a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 17/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17/200] steps=2,006 mse_loss=0.1804, mse_loss_ema=0.1742, logvar_loss=-0.7116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0a5d8686024fe6b995e209337f657c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 18/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18/200] steps=2,124 mse_loss=0.1732, mse_loss_ema=0.1744, logvar_loss=-0.7540\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbd237a43e449a5818cb5f1a5b3babf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 19/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19/200] steps=2,242 mse_loss=0.1600, mse_loss_ema=0.1734, logvar_loss=-0.8307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3b448895714d4788ca6fde3a310c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 20/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20/200] steps=2,360 mse_loss=0.1867, mse_loss_ema=0.1734, logvar_loss=-0.6700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a67fa7798e42bc8c06f7d017830529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 21/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21/200] steps=2,478 mse_loss=0.1578, mse_loss_ema=0.1734, logvar_loss=-0.8436\n",
      "Configuration saved to ./checkpoints/flow_mnist/unet_config.json\n",
      "Model weights saved to ./checkpoints/flow_mnist/unet_model.pt\n",
      "EMA model weights saved to ./checkpoints/flow_mnist/unet_ema.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6f9d211aef4846af8d1db261c8c03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 22/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22/200] steps=2,596 mse_loss=0.1532, mse_loss_ema=0.1724, logvar_loss=-0.8708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3b0552f67e411fa67aeaa265b27820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 23/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23/200] steps=2,714 mse_loss=0.1741, mse_loss_ema=0.1722, logvar_loss=-0.7477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9668fee613ff447dbf5c1dbffa8ab444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 24/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24/200] steps=2,832 mse_loss=0.1563, mse_loss_ema=0.1718, logvar_loss=-0.8528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f4b5ddc5e7415abf00c121e4ffdcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 25/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25/200] steps=2,950 mse_loss=0.1748, mse_loss_ema=0.1719, logvar_loss=-0.7427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689510f38af7483a9b9b698e65ecfecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 26/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 26/200] steps=3,068 mse_loss=0.1761, mse_loss_ema=0.1713, logvar_loss=-0.7365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bafbff12e042e2b6cc8eaaa4eb9c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 27/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27/200] steps=3,186 mse_loss=0.1655, mse_loss_ema=0.1710, logvar_loss=-0.7983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b418ec6fe0645429d99169659c53f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 28/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28/200] steps=3,304 mse_loss=0.1830, mse_loss_ema=0.1711, logvar_loss=-0.6970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd1306e84254f50b670afb242cbc5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 29/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29/200] steps=3,422 mse_loss=0.1783, mse_loss_ema=0.1707, logvar_loss=-0.7230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c19737cea7449980bc4daa01cd8f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 30/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 30/200] steps=3,540 mse_loss=0.1725, mse_loss_ema=0.1709, logvar_loss=-0.7567\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76656b10d7344b93aa615403e5f9dcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 31/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31/200] steps=3,658 mse_loss=0.1819, mse_loss_ema=0.1710, logvar_loss=-0.7005\n",
      "Configuration saved to ./checkpoints/flow_mnist/unet_config.json\n",
      "Model weights saved to ./checkpoints/flow_mnist/unet_model.pt\n",
      "EMA model weights saved to ./checkpoints/flow_mnist/unet_ema.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46056dd2a5a94d64886f5638ed7a6dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep 32/200:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in tqdm(range(epoch), desc=\"Epochs\", position=0):\n",
    "    pbar = tqdm(train_dataloader, desc=f\"ep {ep+1}/{epoch}\", leave=False, position=1)\n",
    "    for step, batch in enumerate(pbar):\n",
    "        optimizer.zero_grad(set_to_none=zero_to_none)\n",
    "\n",
    "        x_1, c = batch\n",
    "        x_1 = x_1.to(device, non_blocking=True).reshape(x_1.shape[0], *data_shape)\n",
    "        x_0 = torch.randn_like(x_1)\n",
    "        t = rf_train.sample_train_time(x_1.shape[0]).to(device, non_blocking=True)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            x_t, dot_x_t = rf_train.get_interpolation(x_0=x_0, x_1=x_1, t=t)\n",
    "            v_pred = rf_train.get_velocity(x_t, t)\n",
    "            log_var = compiled_logvar(t)\n",
    "            log_var = log_var[:, None, None, None]\n",
    "\n",
    "        mse_loss = torch.nn.functional.mse_loss(v_pred.detach(), dot_x_t.detach()).item()\n",
    "        denom = torch.exp(log_var)\n",
    "        sq_err = (v_pred - dot_x_t).pow(2).sum(dim=1)\n",
    "        loss = (sq_err / denom + log_var).mean()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(rf_train.parameters(), grad_clip_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        global_step += 1\n",
    "        cur_nimg += x_1.shape[0]\n",
    "        ema_flow.update(cur_nimg=cur_nimg, batch_size=x_1.shape[0])\n",
    "\n",
    "        loss_val = float(loss.detach().item())\n",
    "        running_loss = loss_val if running_loss is None else smooth_alpha * running_loss + (1 - smooth_alpha) * mse_loss\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"mse_loss\": f\"{mse_loss:.4f}\",\n",
    "            \"mse_loss_ema\": f\"{running_loss:.4f}\",\n",
    "            \"logvar_loss\": f\"{loss_val:.4f}\",\n",
    "            \"steps\": global_step\n",
    "        })\n",
    "\n",
    "    safe_tqdm_write(f\"[epoch {ep+1}/{epoch}] steps={global_step:,} mse_loss={mse_loss:.4f}, mse_loss_ema={running_loss:.4f}, logvar_loss={loss_val:.4f}\")\n",
    "\n",
    "    if ep % 10 == 0:\n",
    "        flow_model.save_pretrained(f\"./checkpoints/flow_mnist\")\n",
    "        ema_flow.save_pretrained(f\"./checkpoints/flow_mnist\")\n",
    "\n",
    "print(f\"Training done. Total steps: {global_step:,}, last loss: {loss_val:.4f}, EMA: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log var\n",
    "time = torch.linspace(0, 1, steps=1000).to(device)\n",
    "with torch.no_grad():\n",
    "    log_var_vals = compiled_logvar(time).cpu().numpy()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(time.cpu().numpy(), log_var_vals)\n",
    "plt.title(\"Log Variance Schedule\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Log Variance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.samplers import EulerSampler, SDESampler\n",
    "\n",
    "ema_flow.apply_shadow()\n",
    "model_inference = flow_model.eval()\n",
    "\n",
    "rf_inference = RectifiedFlow(\n",
    "    data_shape=data_shape,\n",
    "    velocity_field=model_inference,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "euler_sampler = EulerSampler(rf_inference, num_steps=100)\n",
    "sde_sampler = SDESampler(rf_inference, num_steps=200, noise_scale=1000, noise_decay_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb941603",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = torch.randn(30, *data_shape).to(device)\n",
    "\n",
    "x_1_euler = euler_sampler.sample_loop(x_0=x_0).trajectories[-1]\n",
    "x_1_sde = sde_sampler.sample_loop(x_0=x_0).trajectories[-1]\n",
    "\n",
    "print(x_1.shape)  # torch.Size([20, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3903c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectified_flow.utils import plot_cifar_results\n",
    "\n",
    "plot_cifar_results(x_1_euler)\n",
    "plot_cifar_results(x_1_sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851aaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "bs = x_1_euler.shape[0]\n",
    "\n",
    "x_t_euler = x_1_euler.clone()\n",
    "x_t_sde = x_1_sde.clone()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i in range(N):\n",
    "        t = 1. - i / N\n",
    "        v_pred_euler = model_inference(x_t_euler, torch.full((bs,), t, device=device))\n",
    "        v_pred_sde = model_inference(x_t_sde, torch.full((bs,), t, device=device))\n",
    "        \n",
    "        x_t_euler = x_t_euler - v_pred_euler / N\n",
    "        x_t_sde = x_t_sde - v_pred_sde / N\n",
    "\n",
    "plot_cifar_results(x_0)\n",
    "plot_cifar_results(x_t_euler)\n",
    "# plot_cifar_results(torch.abs(x_0 - x_t_euler))\n",
    "plot_cifar_results(x_t_sde)\n",
    "# plot_cifar_results(torch.abs(x_0 - x_t_sde))\n",
    "\n",
    "x0_inv_euler = x_t_euler.detach().reshape(bs, -1)\n",
    "x0_inv_sde   = x_t_sde.detach().reshape(bs, -1)\n",
    "\n",
    "# Plot the norm of x_0_inv\n",
    "norms_euler = x0_inv_euler.norm(dim=1).cpu().numpy()\n",
    "norms_sde   = x0_inv_sde.norm(dim=1).cpu().numpy()\n",
    "\n",
    "lo = float(min(norms_euler.min(), norms_sde.min()))\n",
    "hi = float(max(norms_euler.max(), norms_sde.max()))\n",
    "bins = np.linspace(lo, hi, 100)  # 同数量 & 边界\n",
    "\n",
    "plt.figure(figsize=(6,4), dpi=300)\n",
    "plt.hist(norms_euler, bins=bins, density=True, alpha=0.6,\n",
    "         label='Euler', edgecolor='black', linewidth=0.6)\n",
    "plt.hist(norms_sde,   bins=bins, density=True, alpha=0.6,\n",
    "         label='SDE',   edgecolor='black', linewidth=0.6)\n",
    "plt.xlabel(r'$\\,\\|x_0^{\\mathrm{inv}}\\|_2$')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Recovered noise L2-norm distribution')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i in range(N):\n",
    "        t = i / N\n",
    "\n",
    "        v_pred_euler = model_inference(x_t_euler, torch.full((bs,), t, device=device))\n",
    "        v_pred_sde = model_inference(x_t_sde, torch.full((bs,), t, device=device))\n",
    "\n",
    "        x_t_euler = x_t_euler + v_pred_euler / N\n",
    "        x_t_sde = x_t_sde + v_pred_sde / N\n",
    "\n",
    "plot_cifar_results(x_t_euler)\n",
    "plot_cifar_results(x_t_sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed65aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
