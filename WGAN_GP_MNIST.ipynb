{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea3d19b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment you will explore **Generative Adversarial Networks (GANs)** through a curated, step-by-step notebook. The notebook runs end-to-end out of the box so you can focus on the **ideas** and **observations**, not on boilerplate coding.\n",
    "\n",
    "### Big picture (what you’ll see as you run cells)\n",
    "- **Data → Model → Training → Monitoring → Samples**: we load a simple image dataset, train a generator and a critic with WGAN-GP, track a few curves, and visualize generated images over epochs.\n",
    "- **Why WGAN-GP?** It encourages smooth, stable training by nudging the critic’s gradients toward unit norm, which tends to improve sample quality and reduce pathologies like mode collapse.\n",
    "- **What to pay attention to:** how the samples evolve, how losses behave, and how the gradient penalty relates to stability.\n",
    "\n",
    "### Your job in this notebook\n",
    "1. **Run** the provided cells in order to understand the workflow and see the model learn.\n",
    "2. **Observe & reflect** (brief notes):\n",
    "   - How do samples improve across epochs?\n",
    "   - What do the training curves suggest about stability?\n",
    "   - Do you notice mode collapse or artifacts?\n",
    "\n",
    "### Final task (what you will change)\n",
    "- **Replace the dataset** (e.g., Fashion-MNIST or another small image dataset of similar size, can be your own dataset).\n",
    "- **Train another GAN** configuration of your choice (e.g., switch objective or architecture at a high level; you can reuse most of the notebook flow).\n",
    "- **Report**:\n",
    "  - A few representative sample grids,\n",
    "  - 1–2 concise plots you find most informative,\n",
    "  - **Your own exploration:** try adjusting hyperparameters (e.g., learning rate, betas, batch size, critic updates), modifying architecture (depth/width, normalization, activations), or even proposing a new loss/objective (creative/random attempts are welcome). Summarize what you changed and what you observed.\n",
    "\n",
    "> Keep your discussion conceptual and visual: focus on *what* changes and *why* you think it happens, rather than implementation details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Environment & Utilities ===\n",
    "import os, math, time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataloaders ===\n",
    "def get_mnist_dataloaders(batch_size=128):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),              # (0,1)\n",
    "    ])\n",
    "    train = datasets.MNIST(root='./data/mnist', train=True,  download=True, transform=tfm)\n",
    "    test  = datasets.MNIST(root='./data/mnist', train=False, download=True, transform=tfm)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=2, pin_memory=(device.type=='cuda'), drop_last=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=2, pin_memory=(device.type=='cuda'), drop_last=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_fashion_mnist_dataloaders(batch_size=128):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train = datasets.FashionMNIST(root='./data/fashion', train=True,  download=True, transform=tfm)\n",
    "    test  = datasets.FashionMNIST(root='./data/fashion', train=False, download=True, transform=tfm)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=2, pin_memory=(device.type=='cuda'), drop_last=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=2, pin_memory=(device.type=='cuda'), drop_last=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_lsun_dataloader(path_to_data='./data/lsun', dataset='bedroom_train', batch_size=64):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.CenterCrop(128),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dset = datasets.LSUN(root=path_to_data, classes=[dataset], transform=tfm)\n",
    "    loader = DataLoader(dset, batch_size=batch_size, shuffle=True,\n",
    "                        num_workers=4, pin_memory=(device.type=='cuda'), drop_last=True)\n",
    "    return loader\n",
    "\n",
    "dataset_name = 'mnist'\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "if dataset_name == 'mnist':\n",
    "    train_loader, _ = get_mnist_dataloaders(batch_size=BATCH_SIZE)\n",
    "    IMG_SIZE = (32, 32, 1)\n",
    "elif dataset_name == 'fashion_mnist':\n",
    "    train_loader, _ = get_fashion_mnist_dataloaders(batch_size=BATCH_SIZE)\n",
    "    IMG_SIZE = (32, 32, 1)\n",
    "elif dataset_name == 'lsun':\n",
    "    train_loader = get_lsun_dataloader(batch_to_data='./data/lsun',\n",
    "                                       dataset='bedroom_train', batch_size=BATCH_SIZE)\n",
    "    IMG_SIZE = (128, 128, 3)\n",
    "else:\n",
    "    raise ValueError(\"Unknown dataset_name\")\n",
    "\n",
    "print(f\"Dataset: {dataset_name} | IMG_SIZE = {IMG_SIZE} | batches/epoch ≈ {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1096a9",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "### Generator Network\n",
    "The generator transforms noise $z \\sim \\mathcal{N}(0, I)$ into images that should match the real data distribution.\n",
    "\n",
    "### Discriminator (Critic) Network\n",
    "\n",
    "The discriminator acts as a **Lipschitz function** that estimates the Wasserstein distance between real and generated distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ef0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Models ===\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, dim):\n",
    "        \"\"\"\n",
    "        img_size: (H, W, C)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        H, W, C = img_size\n",
    "        feat_h, feat_w = H // 16, W // 16\n",
    "        assert H % 16 == 0 and W % 16 == 0, \"Image size should be multiples of 16\"\n",
    "        self.dim = dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.feat_h, self.feat_w = int(feat_h), int(feat_w)\n",
    "\n",
    "        self.latent_to_features = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8 * dim * self.feat_h * self.feat_w),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.features_to_image = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8*dim, 4*dim, 4, 2, 1, bias=False), nn.BatchNorm2d(4*dim), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(4*dim, 2*dim, 4, 2, 1, bias=False), nn.BatchNorm2d(2*dim), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(2*dim, 1*dim, 4, 2, 1, bias=False), nn.BatchNorm2d(1*dim), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(1*dim, C, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.latent_to_features(z)\n",
    "        x = x.view(-1, 8 * self.dim, self.feat_h, self.feat_w)\n",
    "        return self.features_to_image(x)\n",
    "\n",
    "    def sample_latent(self, num_samples, device=None):\n",
    "        device = device or next(self.parameters()).device\n",
    "        return torch.randn((num_samples, self.latent_dim), device=device)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, dim):\n",
    "        super().__init__()\n",
    "        H, W, C = img_size\n",
    "        feat_h, feat_w = H // 16, W // 16\n",
    "        assert H % 16 == 0 and W % 16 == 0\n",
    "        self.img_size = img_size\n",
    "        self.feat_h, self.feat_w = int(feat_h), int(feat_w)\n",
    "\n",
    "        self.image_to_features = nn.Sequential(\n",
    "            nn.Conv2d(C, dim, 4, 2, 1), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(dim, 2*dim, 4, 2, 1), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(2*dim, 4*dim, 4, 2, 1), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(4*dim, 8*dim, 4, 2, 1)  # <-- no Sigmoid here\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(8*dim, 1, 1),        # 1x1 conv to 1 channel\n",
    "            nn.AdaptiveAvgPool2d(1),       # Global Average Pooling -> (B,1,1,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.image_to_features(x)\n",
    "        h = self.head(h).view(x.size(0), 1)  # (B,1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training Utils ===\n",
    "@torch.no_grad()\n",
    "def preview_batch(loader, n=32):\n",
    "    x, _ = next(iter(loader))\n",
    "    grid = make_grid(x[:n], nrow=int(math.sqrt(n)), padding=2)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(np.transpose(grid.numpy(), (1,2,0)), cmap='gray')\n",
    "    plt.axis('off'); plt.title('Preview batch'); plt.show()\n",
    "\n",
    "def gradient_penalty(D, real, fake, gp_weight=10.0):\n",
    "    bsz = real.size(0)\n",
    "    alpha = torch.rand(bsz, *([1] * (real.dim() - 1)), device=real.device)\n",
    "    interpolated = alpha * real + (1 - alpha) * fake\n",
    "    interpolated.requires_grad_(True)\n",
    "\n",
    "    d_interpolated = D(interpolated)\n",
    "    grad_outputs = torch.ones_like(d_interpolated, device=real.device)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolated,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(bsz, -1)\n",
    "    grad_norm = gradients.norm(2, dim=1)               # (B,)\n",
    "    gp = gp_weight * ((grad_norm - 1.0) ** 2).mean()\n",
    "    return gp, grad_norm.mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def grid_from_latents(G, latents, nrow=8):\n",
    "    imgs = G(latents).clamp(0,1).cpu()\n",
    "    grid = make_grid(imgs, nrow=nrow, padding=2)\n",
    "    return np.transpose(grid.numpy(), (1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e96233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Trainer (notebook version) ===\n",
    "class Trainer:\n",
    "    def __init__(self, generator, discriminator, gen_optimizer, dis_optimizer,\n",
    "                 gp_weight=10.0, critic_iterations=5, print_every=50, use_cuda=None):\n",
    "        self.G = generator\n",
    "        self.D = discriminator\n",
    "        self.G_opt = gen_optimizer\n",
    "        self.D_opt = dis_optimizer\n",
    "\n",
    "        self.gp_weight = gp_weight\n",
    "        self.critic_iterations = critic_iterations\n",
    "        self.print_every = print_every\n",
    "        self.num_steps = 0\n",
    "\n",
    "        self.use_cuda = (use_cuda if use_cuda is not None else torch.cuda.is_available())\n",
    "        if self.use_cuda:\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "        self.losses = {'G': [], 'D': [], 'GP': [], 'grad_norm': []}\n",
    "\n",
    "    def _critic_train_iteration(self, real_batch):\n",
    "        self.D_opt.zero_grad(set_to_none=True)\n",
    "        bsz = real_batch.size(0)\n",
    "\n",
    "        z = self.G.sample_latent(bsz, device=real_batch.device)\n",
    "        fake = self.G(z)\n",
    "\n",
    "        d_real = self.D(real_batch)\n",
    "        d_fake = self.D(fake.detach())\n",
    "\n",
    "        gp, gnorm = gradient_penalty(self.D, real_batch, fake.detach(), gp_weight=self.gp_weight)\n",
    "\n",
    "        d_loss = d_fake.mean() - d_real.mean() + gp\n",
    "        d_loss.backward()\n",
    "        self.D_opt.step()\n",
    "\n",
    "        self.losses['D'].append(d_loss.item())\n",
    "        self.losses['GP'].append(gp.item())\n",
    "        self.losses['grad_norm'].append(gnorm.item())\n",
    "\n",
    "    def _generator_train_iteration(self, real_batch):\n",
    "        self.G_opt.zero_grad(set_to_none=True)\n",
    "        bsz = real_batch.size(0)\n",
    "        z = self.G.sample_latent(bsz, device=real_batch.device)\n",
    "        fake = self.G(z)\n",
    "        g_loss = - self.D(fake).mean()\n",
    "        g_loss.backward()\n",
    "        self.G_opt.step()\n",
    "        self.losses['G'].append(g_loss.item())\n",
    "\n",
    "    def train(self, data_loader, epochs=200, save_training_gif=True, gif_every_epoch=True, gif_name='training.gif'):\n",
    "        if save_training_gif:\n",
    "            fixed_latents = self.G.sample_latent(64, device=device)\n",
    "            progress_frames = []\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            pbar = tqdm(data_loader, desc=f\"[Epoch {epoch}/{epochs}]\", leave=False)\n",
    "            for i, (data, *_) in enumerate(pbar):\n",
    "                data = data.to(device, non_blocking=True)\n",
    "                self.num_steps += 1\n",
    "\n",
    "                self._critic_train_iteration(data)\n",
    "\n",
    "                if self.num_steps % self.critic_iterations == 0:\n",
    "                    self._generator_train_iteration(data)\n",
    "\n",
    "                if (i % self.print_every == 0) and len(self.losses['G']) > 0:\n",
    "                    pbar.set_postfix(D=f\"{self.losses['D'][-1]:.3f}\",\n",
    "                                     GP=f\"{self.losses['GP'][-1]:.3f}\",\n",
    "                                     G=f\"{self.losses['G'][-1]:.3f}\",\n",
    "                                     gN=f\"{self.losses['grad_norm'][-1]:.2f}\")\n",
    "\n",
    "            if save_training_gif and (gif_every_epoch or epoch == epochs):\n",
    "                frame = grid_from_latents(self.G, fixed_latents, nrow=8)\n",
    "                progress_frames.append((frame * 255).astype(np.uint8))\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                fig, ax = plt.subplots(figsize=(4,4))\n",
    "                ax.imshow(frame, cmap='gray')\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f\"Epoch {epoch}\")\n",
    "                display(fig)\n",
    "                plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a26699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quick Preview ===\n",
    "preview_batch(train_loader, n=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f033796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Instantiate models & optimizers ===\n",
    "LATENT_DIM = 100\n",
    "DIM        = 16\n",
    "LR         = 1e-4\n",
    "BETAS      = (0.9, 0.99)\n",
    "EPOCHS     = 200\n",
    "CRITIC_ITERS = 5\n",
    "GP_WEIGHT    = 10.0\n",
    "PRINT_EVERY  = 50\n",
    "\n",
    "G = Generator(img_size=IMG_SIZE, latent_dim=LATENT_DIM, dim=DIM).to(device)\n",
    "D = Discriminator(img_size=IMG_SIZE, dim=DIM).to(device)\n",
    "\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=LR, betas=BETAS)\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=LR, betas=BETAS)\n",
    "\n",
    "sum_params = lambda m: sum(p.numel() for p in m.parameters())\n",
    "print(G)\n",
    "print(D)\n",
    "print(f\"G params: {sum_params(G):,} | D params: {sum_params(D):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train ===\n",
    "trainer = Trainer(G, D, G_opt, D_opt,\n",
    "                  gp_weight=GP_WEIGHT,\n",
    "                  critic_iterations=CRITIC_ITERS,\n",
    "                  print_every=PRINT_EVERY,\n",
    "                  use_cuda=(device.type=='cuda'))\n",
    "\n",
    "trainer.train(train_loader, epochs=EPOCHS,\n",
    "              save_training_gif=True,\n",
    "              gif_every_epoch=True,\n",
    "              gif_name=f'training_{dataset_name}_{EPOCHS}e.gif')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(trainer.losses['D'], label='D')\n",
    "plt.plot(trainer.losses['GP'], label='GP')\n",
    "plt.legend(); plt.title(\"Discriminator / GP\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(trainer.losses['G'], label='G', color='orange')\n",
    "plt.legend(); plt.title(\"Generator\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
