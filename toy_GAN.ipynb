{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, time, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data: str, batch_size: int = 200, device: str = \"cpu\") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate synthetic 2D datasets without rewards.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : {\"rings\", \"8gaussians\", \"2spirals\", \"checkerboard\"}\n",
    "    batch_size : int\n",
    "    device : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : torch.FloatTensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    def torch_linspace_exclusive(start, stop, steps, device=\"cpu\"):\n",
    "        return torch.linspace(start, stop, steps + 1, device=device)[:-1]\n",
    "\n",
    "    if data == \"rings\":\n",
    "        # split into 4 rings\n",
    "        n4 = n3 = n2 = batch_size // 4\n",
    "        n1 = batch_size - n4 - n3 - n2\n",
    "\n",
    "        angle4 = torch_linspace_exclusive(0, 2 * np.pi, n4, device=device)\n",
    "        angle3 = torch_linspace_exclusive(0, 2 * np.pi, n3, device=device)\n",
    "        angle2 = torch_linspace_exclusive(0, 2 * np.pi, n2, device=device)\n",
    "        angle1 = torch_linspace_exclusive(0, 2 * np.pi, n1, device=device)\n",
    "\n",
    "        circ4 = torch.stack([torch.cos(angle4), torch.sin(angle4)], dim=1)         # r = 1.00\n",
    "        circ3 = torch.stack([torch.cos(angle3), torch.sin(angle3)], dim=1) * 0.75  # r = 0.75\n",
    "        circ2 = torch.stack([torch.cos(angle2), torch.sin(angle2)], dim=1) * 0.50  # r = 0.50\n",
    "        circ1 = torch.stack([torch.cos(angle1), torch.sin(angle1)], dim=1) * 0.25  # r = 0.25\n",
    "\n",
    "        X = torch.cat([circ4, circ3, circ2, circ1], dim=0) * 3.0\n",
    "        X = X + torch.randn_like(X) * 0.08  # small Gaussian noise\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        return X[perm].float()\n",
    "\n",
    "    elif data == \"8gaussians\":\n",
    "        scale = 4.0\n",
    "        centers = torch.tensor([\n",
    "            [0, 1],\n",
    "            [-1/np.sqrt(2),  1/np.sqrt(2)],\n",
    "            [-1, 0],\n",
    "            [-1/np.sqrt(2), -1/np.sqrt(2)],\n",
    "            [0, -1],\n",
    "            [ 1/np.sqrt(2), -1/np.sqrt(2)],\n",
    "            [1, 0],\n",
    "            [ 1/np.sqrt(2),  1/np.sqrt(2)]\n",
    "        ], dtype=torch.float32, device=device) * scale\n",
    "\n",
    "        idx = torch.randint(0, 8, (batch_size,), device=device)\n",
    "        X = torch.randn(batch_size, 2, device=device) * 0.5\n",
    "        X = (X + centers[idx]) / 1.414\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        return X[perm].float()\n",
    "\n",
    "    elif data == \"2spirals\":\n",
    "        half = batch_size // 2\n",
    "        n = torch.sqrt(torch.rand(half, 1, device=device)) * (3 * np.pi)\n",
    "\n",
    "        d1x = -torch.cos(n) * n + torch.rand(half, 1, device=device) * 0.5\n",
    "        d1y =  torch.sin(n) * n + torch.rand(half, 1, device=device) * 0.5\n",
    "        spiral1 = torch.cat([d1x, d1y], dim=1)\n",
    "\n",
    "        spiral2 = -spiral1\n",
    "        X = torch.cat([spiral1, spiral2], dim=0) / 3.0\n",
    "        X = X + torch.randn_like(X) * 0.1\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        # if batch_size is odd, drop the last extra sample after permuting\n",
    "        return X[perm][:batch_size].float()\n",
    "\n",
    "    elif data == \"checkerboard\":\n",
    "        # x1 ~ Uniform([-2, 2])\n",
    "        x1 = torch.rand(batch_size, device=device) * 4 - 2\n",
    "        # x2 with alternating offset by parity of floor(x1)\n",
    "        x2_offset = torch.rand(batch_size, device=device) - (\n",
    "            torch.randint(0, 2, (batch_size,), device=device, dtype=torch.float32) * 2\n",
    "        )\n",
    "        x2 = x2_offset + (torch.floor(x1) % 2)\n",
    "\n",
    "        X = torch.stack([x1, x2], dim=1) * 2\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        return X[perm].float()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset type: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose dataset & dataloader ---\n",
    "data_type = \"checkerboard\"   # \"rings\" | \"8gaussians\" | \"2spirals\" | \"checkerboard\"\n",
    "batch_size = 1024\n",
    "dataset_size = 50000\n",
    "\n",
    "X_real = generate_data(data_type, batch_size=dataset_size, device=\"cpu\")\n",
    "ds = TensorDataset(X_real)  # (N,2)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                num_workers=0, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sub = X_real[:5000].numpy()\n",
    "plt.scatter(sub[:,0], sub[:,1], s=2, alpha=0.6)\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.xlim(-4.3,4.3); plt.ylim(-4.3,4.3)\n",
    "plt.title(f\"Real samples â€¢ {data_type}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGenerator(nn.Module):\n",
    "    def __init__(self, z_dim=16, hidden=(256,256,256), out_dim=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = z_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(in_dim, h), nn.ReLU(inplace=True)]\n",
    "            in_dim = h\n",
    "        layers += [nn.Linear(in_dim, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class MLPDiscriminator(nn.Module):\n",
    "    def __init__(self, in_dim=2, hidden=(256,256,256)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.LeakyReLU(0.2, inplace=True)]\n",
    "            d = h\n",
    "        layers += [nn.Linear(d, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, a=0.2, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "z_dim = 16\n",
    "G = MLPGenerator(z_dim=z_dim).to(device)\n",
    "D = MLPDiscriminator().to(device)\n",
    "G.apply(weights_init); D.apply(weights_init)\n",
    "\n",
    "sum_params = lambda m: sum(p.numel() for p in m.parameters())\n",
    "print(f\"G params: {sum_params(G):,} | D params: {sum_params(D):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d30932",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "beta1, beta2 = 0.5, 0.999\n",
    "epochs = 500\n",
    "n_critic = 1\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "bce_logits = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def sample_noise(n, z_dim, device):\n",
    "    return torch.randn(n, z_dim, device=device)\n",
    "\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "viz_noise = sample_noise(5000, z_dim, device)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    G.train(); D.train()\n",
    "    pbar = tqdm(dl, desc=f\"[Epoch {epoch}/{epochs}]\", leave=False)\n",
    "    for real_batch, in pbar:\n",
    "        real = real_batch.to(device, non_blocking=True)     # (B,2)\n",
    "        B = real.size(0)\n",
    "\n",
    "        # ===== 1) Update Discriminator =====\n",
    "        for _ in range(n_critic):\n",
    "            z = sample_noise(B, z_dim, device)\n",
    "            with torch.no_grad():\n",
    "                fake_detached = G(z)                        # (B,2)\n",
    "\n",
    "            D_real = D(real)                                # logits\n",
    "            D_fake = D(fake_detached)\n",
    "\n",
    "            d_loss = bce_logits(D_real, torch.ones_like(D_real)) + \\\n",
    "                     bce_logits(D_fake, torch.zeros_like(D_fake))\n",
    "\n",
    "            opt_D.zero_grad(set_to_none=True)\n",
    "            d_loss.backward()\n",
    "            opt_D.step()\n",
    "\n",
    "        # ===== 2) Update Generator (non-saturating) =====\n",
    "        z = sample_noise(B, z_dim, device)\n",
    "        fake = G(z)\n",
    "        D_fake_for_G = D(fake)\n",
    "        g_loss = bce_logits(D_fake_for_G, torch.ones_like(D_fake_for_G))\n",
    "\n",
    "        opt_G.zero_grad(set_to_none=True)\n",
    "        g_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        g_losses.append(g_loss.item()); d_losses.append(d_loss.item())\n",
    "        pbar.set_postfix(d=f\"{d_loss.item():.3f}\", g=f\"{g_loss.item():.3f}\")\n",
    "\n",
    "    # Visualization every few epochs\n",
    "    if epoch % 20 == 0 or epoch == 1:\n",
    "        G.eval()\n",
    "        with torch.no_grad():\n",
    "            fake_viz = G(viz_noise).detach().cpu().numpy()\n",
    "        real_viz = X_real[:5000].numpy()\n",
    "\n",
    "        plt.figure(figsize=(15,4))\n",
    "        # left: real\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.scatter(real_viz[:,0], real_viz[:,1], s=2, alpha=0.6)\n",
    "        plt.title(f\"Real â€¢ {data_type}\")\n",
    "        plt.xlim(-5,5); plt.ylim(-5,5); plt.gca().set_aspect('equal','box')\n",
    "\n",
    "        # middle: discriminator contour (sigmoid of logits)\n",
    "        plt.subplot(1,3,2)\n",
    "        grid_n = 200\n",
    "        xs = np.linspace(-5, 5, grid_n)\n",
    "        ys = np.linspace(-5, 5, grid_n)\n",
    "        xx, yy = np.meshgrid(xs, ys)\n",
    "        grid = np.stack([xx.ravel(), yy.ravel()], axis=1).astype(np.float32)\n",
    "        grid_t = torch.from_numpy(grid).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = D(grid_t)\n",
    "            probs = torch.sigmoid(logits).view(grid_n, grid_n).detach().cpu().numpy()\n",
    "        im = plt.contourf(xs, ys, probs, levels=20, alpha=0.9)\n",
    "        plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "        plt.title(\"Discriminator Contour\")\n",
    "        plt.xlim(-5,5); plt.ylim(-5,5); plt.gca().set_aspect('equal','box')\n",
    "\n",
    "        # right: fake\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.scatter(fake_viz[:,0], fake_viz[:,1], s=2, alpha=0.6)\n",
    "        plt.title(f\"GAN samples @ epoch {epoch}\")\n",
    "        plt.xlim(-5,5); plt.ylim(-5,5); plt.gca().set_aspect('equal','box')\n",
    "\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(d_losses, label=\"D\"); plt.plot(g_losses, label=\"G\")\n",
    "plt.legend(); plt.title(\"Training losses\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.load_state_dict(torch.load(f\"./weight/ganG_{data_type}.pth\", map_location=device)); G.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def gan_sample(n=5000, z_dim=16, device=device):\n",
    "    G.eval()\n",
    "    z = torch.randn(n, z_dim, device=device)\n",
    "    x = G(z).detach().cpu().numpy()\n",
    "    return x\n",
    "\n",
    "fake = gan_sample(n=10000, z_dim=z_dim, device=device)\n",
    "plt.figure(figsize=(4.5,4.5))\n",
    "plt.scatter(fake[:,0], fake[:,1], s=2, alpha=0.6)\n",
    "plt.gca().set_aspect('equal','box')\n",
    "plt.xlim(-5,5); plt.ylim(-5,5)\n",
    "plt.title(\"Samples from trained GAN\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
