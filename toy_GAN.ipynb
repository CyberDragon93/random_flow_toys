{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, time, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data: str, batch_size: int = 200, device: str = \"cpu\") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate synthetic 2D datasets without rewards.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : {\"rings\", \"8gaussians\", \"2spirals\", \"checkerboard\"}\n",
    "    batch_size : int\n",
    "    device : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : torch.FloatTensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    def torch_linspace_exclusive(start, stop, steps, device=\"cpu\"):\n",
    "        return torch.linspace(start, stop, steps + 1, device=device)[:-1]\n",
    "\n",
    "    if data == \"rings\":\n",
    "        # split into 4 rings\n",
    "        n4 = n3 = n2 = batch_size // 4\n",
    "        n1 = batch_size - n4 - n3 - n2\n",
    "\n",
    "        angle4 = torch_linspace_exclusive(0, 2 * np.pi, n4, device=device)\n",
    "        angle3 = torch_linspace_exclusive(0, 2 * np.pi, n3, device=device)\n",
    "        angle2 = torch_linspace_exclusive(0, 2 * np.pi, n2, device=device)\n",
    "        angle1 = torch_linspace_exclusive(0, 2 * np.pi, n1, device=device)\n",
    "\n",
    "        circ4 = torch.stack([torch.cos(angle4), torch.sin(angle4)], dim=1)         # r = 1.00\n",
    "        circ3 = torch.stack([torch.cos(angle3), torch.sin(angle3)], dim=1) * 0.75  # r = 0.75\n",
    "        circ2 = torch.stack([torch.cos(angle2), torch.sin(angle2)], dim=1) * 0.50  # r = 0.50\n",
    "        circ1 = torch.stack([torch.cos(angle1), torch.sin(angle1)], dim=1) * 0.25  # r = 0.25\n",
    "\n",
    "        X = torch.cat([circ4, circ3, circ2, circ1], dim=0) * 3.0\n",
    "        X = X + torch.randn_like(X) * 0.08  # small Gaussian noise\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        return X[perm].float()\n",
    "\n",
    "    elif data == \"8gaussians\":\n",
    "        scale = 4.0\n",
    "        centers = torch.tensor([\n",
    "            [0, 1],\n",
    "            [-1/np.sqrt(2),  1/np.sqrt(2)],\n",
    "            [-1, 0],\n",
    "            [-1/np.sqrt(2), -1/np.sqrt(2)],\n",
    "            [0, -1],\n",
    "            [ 1/np.sqrt(2), -1/np.sqrt(2)],\n",
    "            [1, 0],\n",
    "            [ 1/np.sqrt(2),  1/np.sqrt(2)]\n",
    "        ], dtype=torch.float32, device=device) * scale\n",
    "\n",
    "        idx = torch.randint(0, 8, (batch_size,), device=device)\n",
    "        X = torch.randn(batch_size, 2, device=device) * 0.5\n",
    "        X = (X + centers[idx]) / 1.414\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        return X[perm].float()\n",
    "\n",
    "    elif data == \"2spirals\":\n",
    "        half = batch_size // 2\n",
    "        n = torch.sqrt(torch.rand(half, 1, device=device)) * (3 * np.pi)\n",
    "\n",
    "        d1x = -torch.cos(n) * n + torch.rand(half, 1, device=device) * 0.5\n",
    "        d1y =  torch.sin(n) * n + torch.rand(half, 1, device=device) * 0.5\n",
    "        spiral1 = torch.cat([d1x, d1y], dim=1)\n",
    "\n",
    "        spiral2 = -spiral1\n",
    "        X = torch.cat([spiral1, spiral2], dim=0) / 3.0\n",
    "        X = X + torch.randn_like(X) * 0.1\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        # if batch_size is odd, drop the last extra sample after permuting\n",
    "        return X[perm][:batch_size].float()\n",
    "\n",
    "    elif data == \"checkerboard\":\n",
    "        # x1 ~ Uniform([-2, 2])\n",
    "        x1 = torch.rand(batch_size, device=device) * 4 - 2\n",
    "        # x2 with alternating offset by parity of floor(x1)\n",
    "        x2_offset = torch.rand(batch_size, device=device) - (\n",
    "            torch.randint(0, 2, (batch_size,), device=device, dtype=torch.float32) * 2\n",
    "        )\n",
    "        x2 = x2_offset + (torch.floor(x1) % 2)\n",
    "\n",
    "        X = torch.stack([x1, x2], dim=1) * 2\n",
    "\n",
    "        perm = torch.randperm(X.size(0), device=device)\n",
    "        return X[perm].float()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset type: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose dataset & dataloader ---\n",
    "data_type = \"2spirals\"   # \"rings\" | \"8gaussians\" | \"2spirals\" | \"checkerboard\"\n",
    "batch_size = 1024\n",
    "dataset_size = 50000\n",
    "\n",
    "X_real = generate_data(data_type, batch_size=dataset_size, device=\"cpu\")\n",
    "ds = TensorDataset(X_real)  # (N,2)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                num_workers=0, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sub = X_real[:5000].numpy()\n",
    "plt.scatter(sub[:,0], sub[:,1], s=2, alpha=0.6)\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.xlim(-4.3,4.3); plt.ylim(-4.3,4.3)\n",
    "plt.title(f\"Real samples • {data_type}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGenerator(nn.Module):\n",
    "    def __init__(self, z_dim=16, hidden=(256,256,256), out_dim=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = z_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(in_dim, h), nn.ReLU(inplace=True)]\n",
    "            in_dim = h\n",
    "        layers += [nn.Linear(in_dim, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class MLPDiscriminator(nn.Module):\n",
    "    def __init__(self, in_dim=2, hidden=(256,256,256)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.LeakyReLU(0.2, inplace=True)]\n",
    "            d = h\n",
    "        layers += [nn.Linear(d, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, a=0.2, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "def sample_noise(n, z_dim, device):\n",
    "    return torch.randn(n, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aaab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualization utilities ===\n",
    "from ipywidgets import IntSlider, Play, jslink, HBox, VBox, HTML, Output\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def make_grid(xmin=-4.1, xmax=4.1, ymin=-4.1, ymax=4.1, n=140, device=\"cpu\"):\n",
    "    xs = np.linspace(xmin, xmax, n)\n",
    "    ys = np.linspace(ymin, ymax, n)\n",
    "    xx, yy = np.meshgrid(xs, ys)\n",
    "    grid = np.stack([xx.ravel(), yy.ravel()], axis=1).astype(np.float32)\n",
    "    grid_t = torch.from_numpy(grid).to(device)\n",
    "    return xs, ys, grid_t\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def capture_snapshot(G, D, X_real, viz_noise, xs, ys, grid_t, data_type, device, epoch):\n",
    "    G.eval(); D.eval()\n",
    "    fake_viz = G(viz_noise).detach().cpu().numpy()\n",
    "    real_viz = X_real[:len(viz_noise)].detach().cpu().numpy()\n",
    "    scores   = D(grid_t).view(len(ys), len(xs)).detach().cpu().numpy()\n",
    "    return {\n",
    "        \"epoch\": int(epoch),\n",
    "        \"data_type\": data_type,\n",
    "        \"real\": real_viz,\n",
    "        \"fake\": fake_viz,\n",
    "        \"xs\": xs, \"ys\": ys, \"scores\": scores,\n",
    "    }\n",
    "\n",
    "\n",
    "def init_live_browser():\n",
    "    import ipywidgets as W\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "    out = Output()\n",
    "    fig, (ax_real, ax_score, ax_fake) = plt.subplots(1, 3, figsize=(15,4))\n",
    "    fig.subplots_adjust(wspace=0.35)\n",
    "\n",
    "    cax = inset_axes(ax_score, width=\"3%\", height=\"90%\", loc='right', borderpad=1)\n",
    "\n",
    "    info   = W.HTML(value=\"Ready\")\n",
    "    play   = W.Play(interval=400, value=0, min=0, max=0, step=1, description=\"▶\")\n",
    "    slider = W.IntSlider(value=0, min=0, max=0, step=1,\n",
    "                         description=\"epoch idx\", continuous_update=True)\n",
    "\n",
    "    W.link((play, 'value'), (slider, 'value'))\n",
    "\n",
    "    snapshots = []\n",
    "    state = {\"cbar\": None}\n",
    "\n",
    "    def draw_idx(idx):\n",
    "        snap = snapshots[idx]\n",
    "        xs, ys = snap[\"xs\"], snap[\"ys\"]\n",
    "\n",
    "        ax_real.clear()\n",
    "        ax_real.set_title(f\"Real • {snap['data_type']}\")\n",
    "        ax_real.scatter(snap[\"real\"][:,0], snap[\"real\"][:,1], s=2, alpha=0.6)\n",
    "        ax_real.set_xlim(-4.1,4.1); ax_real.set_ylim(-4.1,4.1); ax_real.set_aspect('equal','box')\n",
    "\n",
    "        ax_score.clear()\n",
    "        ax_score.set_title(\"Discriminator Score\")\n",
    "        cf = ax_score.contourf(xs, ys, snap[\"scores\"], levels=20, alpha=0.9)\n",
    "        ax_score.set_xlim(-4.1,4.1); ax_score.set_ylim(-4.1,4.1); ax_score.set_aspect('equal','box')\n",
    "        if state[\"cbar\"] is None:\n",
    "            state[\"cbar\"] = fig.colorbar(cf, cax=cax)\n",
    "        else:\n",
    "            state[\"cbar\"].update_normal(cf)\n",
    "\n",
    "        ax_fake.clear()\n",
    "        ax_fake.set_title(f\"Samples @ epoch {snap['epoch']}\")\n",
    "        ax_fake.scatter(snap[\"fake\"][:,0], snap[\"fake\"][:,1], s=2, alpha=0.6)\n",
    "        ax_fake.set_xlim(-4.1,4.1); ax_fake.set_ylim(-4.1,4.1); ax_fake.set_aspect('equal','box')\n",
    "\n",
    "        info.value = f\"Epoch <b>{snap['epoch']}</b>  |  Snapshots: {len(snapshots)}\"\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    def on_slider(change):\n",
    "        if change[\"name\"] == \"value\" and snapshots:\n",
    "            draw_idx(change[\"new\"])\n",
    "\n",
    "    slider.observe(on_slider, names=\"value\")\n",
    "\n",
    "    def push_snapshot(snap):\n",
    "        snapshots.append(snap)\n",
    "        new_max = len(snapshots) - 1\n",
    "        slider.max = new_max\n",
    "        play.max   = new_max\n",
    "        play.value = new_max\n",
    "\n",
    "        if not snapshots:\n",
    "            with out:\n",
    "                out.clear_output(wait=True)\n",
    "                display(fig)\n",
    "\n",
    "    ui = W.VBox([W.HBox([play, slider, info]), out])\n",
    "    display(ui)\n",
    "    return push_snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb716772",
   "metadata": {},
   "source": [
    "## Vanilla GAN (Optional, you can play with it if you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 16\n",
    "G = MLPGenerator(z_dim=z_dim).to(device)\n",
    "D = MLPDiscriminator().to(device)\n",
    "G.apply(weights_init); D.apply(weights_init)\n",
    "\n",
    "sum_params = lambda m: sum(p.numel() for p in m.parameters())\n",
    "print(f\"G params: {sum_params(G):,} | D params: {sum_params(D):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d30932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualization setup ===\n",
    "VIZ_GRID_N = 140\n",
    "xs, ys, grid_t = make_grid(n=VIZ_GRID_N, device=device)\n",
    "viz_noise = torch.randn(5000, z_dim, device=device)\n",
    "push_snapshot = init_live_browser()   \n",
    "\n",
    "# === Vanilla GAN training ===\n",
    "lr = 2e-4\n",
    "beta1, beta2 = 0.5, 0.999\n",
    "epochs = 500\n",
    "n_critic = 1\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "bce_logits = nn.BCEWithLogitsLoss()\n",
    "\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    G.train(); D.train()\n",
    "    pbar = tqdm(dl, desc=f\"[Epoch {epoch}/{epochs}]\", leave=False)\n",
    "    for real_batch, in pbar:\n",
    "        real = real_batch.to(device, non_blocking=True)     # (B,2)\n",
    "        B = real.size(0)\n",
    "\n",
    "        # ===== 1) Update Discriminator =====\n",
    "        for _ in range(n_critic):\n",
    "            z = torch.randn(B, z_dim, device=device)\n",
    "            with torch.no_grad():\n",
    "                fake_detached = G(z)                        # (B,2)\n",
    "            D_real = D(real)                                # logits\n",
    "            D_fake = D(fake_detached)\n",
    "            d_loss = bce_logits(D_real, torch.ones_like(D_real)) + \\\n",
    "                     bce_logits(D_fake, torch.zeros_like(D_fake))\n",
    "            opt_D.zero_grad(set_to_none=True)\n",
    "            d_loss.backward()\n",
    "            opt_D.step()\n",
    "\n",
    "        # ===== 2) Update Generator (non-saturating) =====\n",
    "        z = torch.randn(B, z_dim, device=device)\n",
    "        fake = G(z)\n",
    "        D_fake_for_G = D(fake)\n",
    "        g_loss = bce_logits(D_fake_for_G, torch.ones_like(D_fake_for_G))\n",
    "        opt_G.zero_grad(set_to_none=True)\n",
    "        g_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        g_losses.append(g_loss.item()); d_losses.append(d_loss.item())\n",
    "        pbar.set_postfix(d=f\"{d_loss.item():.3f}\", g=f\"{g_loss.item():.3f}\")\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs:\n",
    "        snap = capture_snapshot(G, D, X_real, viz_noise, xs, ys, grid_t, data_type, device, epoch)\n",
    "        push_snapshot(snap)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(d_losses, label=\"D\"); plt.plot(g_losses, label=\"G\")\n",
    "plt.legend(); plt.title(\"Training losses\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7f4bd",
   "metadata": {},
   "source": [
    "## WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95925f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 16\n",
    "G = MLPGenerator(z_dim=z_dim).to(device)\n",
    "D = MLPDiscriminator().to(device)\n",
    "G.apply(weights_init); D.apply(weights_init)\n",
    "\n",
    "sum_params = lambda m: sum(p.numel() for p in m.parameters())\n",
    "print(f\"G params: {sum_params(G):,} | D params: {sum_params(D):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56525c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization setup ---\n",
    "VIZ_GRID_N = 140\n",
    "xs, ys, grid_t = make_grid(n=VIZ_GRID_N, device=device)\n",
    "viz_noise = torch.randn(5000, z_dim, device=device)\n",
    "push_snapshot = init_live_browser()   \n",
    "\n",
    "# --- WGAN-GP settings ---\n",
    "lr_G, lr_D = 1e-4, 1e-4\n",
    "beta1, beta2 = 0.0, 0.9\n",
    "n_critic = 2\n",
    "gp_lambda = 1.0\n",
    "\n",
    "one_side_gp = False\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "\n",
    "# --- WGAN-GP gradient penalty ---\n",
    "def gradient_penalty(D, real, fake, one_side=True, return_norm=False):\n",
    "    B = real.size(0)\n",
    "    mixing = torch.rand(B, *([1] * (real.dim() - 1)), device=real.device)\n",
    "    x_hat = mixing * real + (1.0 - mixing) * fake\n",
    "    x_hat.requires_grad_(True)\n",
    "\n",
    "    d_hat = D(x_hat)\n",
    "    grad_outputs = torch.ones_like(d_hat, device=x_hat.device)\n",
    "\n",
    "    grads = torch.autograd.grad(\n",
    "        outputs=d_hat,\n",
    "        inputs=x_hat,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gn = grads.flatten(1).norm(2, dim=1)\n",
    "    if one_side:\n",
    "        gp = torch.nn.functional.relu(gn - 1).pow(2).mean()\n",
    "    else:\n",
    "        gp = (gn - 1.0).pow(2).mean()\n",
    "\n",
    "    return (gp, gn.mean()) if return_norm else gp\n",
    "\n",
    "\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    G.train(); D.train()\n",
    "    pbar = tqdm(dl, desc=f\"[Epoch {epoch}/{epochs}]\", leave=False)\n",
    "\n",
    "    for real_batch, in pbar:\n",
    "        real = real_batch.to(device, non_blocking=True)     # (B,2)\n",
    "        B = real.size(0)\n",
    "\n",
    "        # ===== 1) Update Critic n_critic times =====\n",
    "        for _ in range(n_critic):\n",
    "            z = torch.randn(B, z_dim, device=device)\n",
    "            with torch.no_grad():\n",
    "                fake_detached = G(z)\n",
    "\n",
    "            D_real = D(real).view(-1)\n",
    "            D_fake = D(fake_detached).view(-1)\n",
    "\n",
    "            W = D_real.mean() - D_fake.mean()\n",
    "            gp, gn_mean = gradient_penalty(\n",
    "                D, real, fake_detached,\n",
    "                one_side=one_side_gp\n",
    "                return_norm=True\n",
    "            )\n",
    "\n",
    "            drift = 0.001 * (D_real.pow(2).mean())\n",
    "            d_loss = (D_fake.mean() - D_real.mean()) + gp_lambda * gp + drift\n",
    "\n",
    "            opt_D.zero_grad(set_to_none=True)\n",
    "            d_loss.backward()\n",
    "            opt_D.step()\n",
    "\n",
    "        # ===== 2) Update Generator =====\n",
    "        z = torch.randn(B, z_dim, device=device)\n",
    "        fake = G(z)\n",
    "        g_loss = - D(fake).view(-1).mean()\n",
    "\n",
    "        opt_G.zero_grad(set_to_none=True)\n",
    "        g_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        g_losses.append(g_loss.item()); d_losses.append(d_loss.item())\n",
    "        pbar.set_postfix(\n",
    "            d=f\"{d_loss.item():.3f}\",\n",
    "            g=f\"{g_loss.item():.3f}\",\n",
    "            W=f\"{W.item():.3f}\",\n",
    "            gp=f\"{gp.item():.3f}\",\n",
    "            gn=f\"{gn_mean.item():.2f}\",\n",
    "        )\n",
    "        pbar.set_postfix(d=f\"{d_loss.item():.3f}\", g=f\"{g_loss.item():.3f}\")\n",
    "\n",
    "    # Visualization every few epochs\n",
    "    if epoch % 10 == 0 or epoch == epochs:\n",
    "        snap = capture_snapshot(G, D, X_real, viz_noise, xs, ys, grid_t, data_type, device, epoch)\n",
    "        push_snapshot(snap)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(d_losses, label=\"Critic (D)\"); plt.plot(g_losses, label=\"G\")\n",
    "plt.legend(); plt.title(\"WGAN-GP Training losses\"); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
